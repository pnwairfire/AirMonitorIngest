---
title: "AQS 88101 'Known Locations'"
author: "Jonathan Callahan"
date: "September 27, 2021"
output:
  html_document:
    toc: TRUE
    toc_depth: 3
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The USFS [AirFire](https://www.airfire.org) group is focused on air quality 
associated with wildfire smoke and maintains both historical and 
real-time databases of air quality monitoring
data obtained from stationary monitors (_i.e._ not _"mobile monitors"_). This data
is used in operational displays and for retrospective analysis. Data ingest
and management of air quality "stationary time series" is thus an important ongoing activity.

Challenges include:
 * Location stability -- jitter in reported longitude and latitude coming from GPS.
 * Data duplication -- data from an individual monitor arriving through separate data streams.
 * CPU-intense spatial searches for data such as time zone.
 
To address these and other issues, we are creating a "known locations" table -- 
a set of which locations which have been vetted for reuse by AirFire and for which
all CPU-intensive spatial queries have already been performed.

Isolating purely spatial information from monitor-related information will allow
us to quickly assign incoming data to a "known location" and immediately retrieve
associated spatial data that would otherwise require expensive spatial calculations.

The basic concept for creating a _"known locations"_ table is described in the introduction to the 
[MazamaLocationUtils](https://mazamascience.github.io/MazamaLocationUtils/)
R package.

Because the focus is on wildifres, the spatial scale of interest is >= 500 meters and
each "known location" will be understood to represent a circle with a radius of 
250 meters. Any incoming data records whose longitude and latitude fall within 
250m of an existing location wll assigned to that "known location". New "known locations"
will be added as needed.

## Setup

```{r mazama_setup, message = FALSE}
library(MazamaCoreUtils)

library(AirMonitorIngest)

# Create a directory specifically for EPA data
dir.create("~/Data/EPA", showWarnings = FALSE, recursive = TRUE)
```

We will begin with an existing database of EPA AQS site information. This 
database is assumed to be largely well vetted and contain most of the relevant spatial 
information we will need for further data processing and visualization.

## Download Data

### AQS sites

The `AQS_sites` table contains primarily spatial location information with additional
_"site"_ information that is specific to an individual monitor, _e.g._
`Owning Agency`. As we will see, it is possible to have multiple _"sites"_ at a 
single _"known location"_.

```{r AQS_sites, message = FALSE, results = "hold"}
# Get site metadata
AQS_sites <- epa_getAQSSites(downloadDir = "~/Data/EPA")

dim(AQS_sites)
names(AQS_sites)
```

### AQS Monitors

The `AQS_monitors` table mixes monitor-specific information like `Parameter Code`
and `Last Sample Data` with location-specific information like `State Code` or
`CBSA Name`.

```{r AQS_monitors, message = FALSE, results = "hold"}
# Get monitor metadata
AQS_monitors <- epa_getAQSMonitors(downloadDir = "~/Data/EPA")

dim(AQS_monitors)
names(AQS_monitors)
```

### AQS Parameter Codes

The `AQS_parameterCodes` table provides detailed information on each individual
parameter (pollutant) found in the AQS data.

```{r AQS_parameterCodes, message = FALSE, results = "hold"}
# Get parameter codes
AQS_parameterCodes <- epa_getAQSCodes(tableName = "parameters")

dim(AQS_parameterCodes)
names(AQS_parameterCodes)
```

----

## Explore `AQS_monitors`

### Parameter Codes

The two most important parameter codes for AirFire PM2.5 measurements are
`"88101"` and `"88502"`. 

#### 88101

```{r parameter_88101, results = "hold"}
AQS_parameterCodes %>%
  dplyr::filter(`Parameter Code` %in% c("88101")) %>% 
  dplyr::glimpse()
```

#### 88502

```{r parameter_88502, results = "hold"}
AQS_parameterCodes %>%
  dplyr::filter(`Parameter Code` %in% c("88502")) %>% 
  dplyr::glimpse()
```

### Measurement Scale

As seen in the output below, `Measurement Scale` provides important 
information on the appropriate use of data from a particular monitor. The 
AirFire _"known locations"_ table will be used in the context of wildfire smoke
over large regions. For this use case, we will ignore measurement scales < 500m.

```{r measurement_scale, results = "hold"}
AQS_monitors %>%
  dplyr::mutate(scale_definition = paste(`Measurement Scale`, `Measurement Scale Definition`, sep = ' -- ')) %>%
  dplyr::pull(`scale_definition`) %>%
  unique() %>% sort()
```

----

## Subset for Sites with Parameter Code 88101

### Subset Monitors

We begin by subsetting `AQS_monitors` to include only those monitors used in
regulatory decision making -- PM2.5 FRM/FEM or `88101` and only those associated
with `POC == ` -- the first monitor deployed at an AQS _site_. We will use state,
county and site information to create an `AQSID` which is typically associated
with a monitor-site. The `AQSID can be created for both `AQS_monitors` and
`AQS_sites`, allowing us to create queries combining the two.

```{r AQS_monitors_0, results = "hold"}
AQS_monitors_0 <-
  AQS_monitors %>%
  # Subset
  dplyr::filter(`Measurement Scale` != "MICROSCALE") %>%
  dplyr::filter(`Measurement Scale` != "MIDDLE SCALE") %>%
  dplyr::filter(`Parameter Code` == "88101") %>%
  dplyr::filter(`POC` == "1") %>%
  # Add AQSID as a unique identifier
  dplyr::mutate(
    AQSID = paste0(`State Code`, `County Code`, `Site Number`)
  )

dim(AQS_monitors_0)
```

### Subset Sites

```{r AQS_sites_0, results = "hold"}
AQS_sites_0 <-
  AQS_sites %>%
  # Add AQSID as a unique identifier
  dplyr::mutate(
    AQSID = paste0(`State Code`, `County Code`, `Site Number`)
  ) %>%
  # Subset
  dplyr::filter(AQSID %in% AQS_monitors_0$AQSID)

dim(AQS_sites_0)
```

----

## Create a "Known Locations" Table

We will build a standardized _"known locations"_ table using the 
*MazamaLocationUtils*. This will involve:

* creating standardized variables
* adding spatial metadata

We begin by initializing *MazamaLocationUtils* and associated datasets and
then display the column names we need to create.

```{r known_location_columns, results = "hold"}
library(MazamaSpatialUtils)
library(MazamaLocationUtils)

# Set up spatial data
MazamaLocationUtils::mazama_initialize("~/Data/Spatial")

# Print out names for an empty "known locations" table
known_location_columns <-
  MazamaLocationUtils::table_initialize() %>% 
  names()
```

### Create Standard Variables

The recipe below performs this in stages primarily using functions from *dplyr*.

```{r harmonizing_variables, results = "hold"}
known_locations_0 <-
  
  # Start with AQS_sites_0
  AQS_sites_0 %>%

  # Rename all existing columns with "AQS_"
  dplyr::rename_all(make.names) %>%
  dplyr::rename_all(~ gsub("^", "AQS_", .x)) %>%

  # Add "known location" columns derived from AQS columns where possible
  dplyr::mutate(
    locationID = as.character(NA),
    locationName = AQS_Local.Site.Name,
    longitude = AQS_Longitude,
    latitude = AQS_Latitude,
    elevation = AQS_Elevation,
    countryCode = as.character(NA),
    stateCode = MazamaSpatialUtils::US_stateFIPSToCode(AQS_State.Code),
    county = AQS_County.Name,
    timezone = as.character(NA),
    houseNumber = as.character(NA),
    street = as.character(NA),
    city = AQS_City.Name,
    zip = AQS_Zip.Code
  )
```

For convenience of use with `View()`, we will reorganize the columns with "known location" columns
first and get a sense of our data by creating a map of all locations:

```{r reorganize_columns, results = "hold"}
# Get "AQS_" columns
AQS_columns <-
  names(known_locations_0) %>%
  stringr::str_subset("AQS_.*")

# Reorder column names
known_locations_0 <-
  known_locations_0 %>%
  dplyr::select(dplyr::all_of(c(known_location_columns, AQS_columns)))

plot(
  known_locations_0$longitude, known_locations_0$latitude, 
  pch = 15, cex = 0.5, col  = "red",
  xlab = "", ylab = "",
  main = "AQS 88101 Known Locations"
)

maps::map("world", add = TRUE)
```

### Add/fix Required Columns

Several columns of data were set to `NA` when we created `known_locations_0`.
These columns require a bit more work and are dealt with here:

```{r fix_columns, results = "markdown"}
# Add ISO countryCodes
known_locations_0$countryCode <-
  dplyr::case_when(
    known_locations_0$AQS_State.Code == "66" ~ "GU",
    known_locations_0$AQS_State.Code == "72" ~ "PR",
    known_locations_0$AQS_State.Code == "78" ~ "VI",
    known_locations_0$AQS_State.Code == "80" ~ "MX",
    known_locations_0$AQS_State.Code == "CC" ~ "CA",
    TRUE ~ "US" # default
  )

# Add unique identifiers
known_locations_0$locationID <-
  MazamaLocationUtils::location_createID(
    known_locations_0$longitude,
    known_locations_0$latitude
  )

# Add timezones
known_locations_0$timezone <-
  MazamaSpatialUtils::getTimezone(
    known_locations_0$longitude,
    known_locations_0$latitude,
    # NOTE:  EPA has monitors from US, Canada, Mexico, Puerto Rico, Virgin Islands and Guam
    countryCodes = c("US", "CA", "MX", "PR", "VI", "GU"),
    useBuffering = TRUE
)

# TODO:  Fix stateCode where countryCode != "US"
```

### Review

It's now time to review our first pass table, `known_locations_0`:

```{r first_pass_review}
# What country codes to we have?
table(known_locations_0$countryCode)

# Are all locations unique?
any(duplicated(known_locations_0$locationID))
```
## Impose 500 Meter Separation

As described in the Introduction, we want the AirFire "known locations" table to
have a measurement scale >= 500 meters. We will use functions from
*MazamaLocationUtils* to identify overlapping locations and deal with them on an
individual basis.

### Finding Overlapping Locations

```{r find_overlapping}
tbl <- 
  dplyr::select(known_locations_0, longitude, latitude) %>%
  MazamaLocationUtils::table_findOverlappingLocations(radius = 250)

print(tbl)
```

